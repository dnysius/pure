{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angle Dependence\n",
    "1. How do you set up the experiment?\n",
    "\n",
    "The setup consists of a metal sample with a micrometer built-in which tilts the sample in a large bucket of water. To increase repeatability, we mark the position of the sample on the bottom surface of the bucket with tape and other pieces of metal.\n",
    "\n",
    "We use a protractor to measure the micrometer reading corresponding to every degree of inclination, starting at 0 degrees and going up to 15 degrees. We perform a linear fit on this data using `scipy.optimize.curve_fit()` and a linear model function $f(\\theta) = a\\theta+b$, where $\\theta$ is the angle of inclination and $f$ is the micrometer reading.\n",
    "\n",
    "2. How do you collect data for the angle dependence experiment?\n",
    "\n",
    "Using the angle to micrometer reading table, we rotate the micrometer to fit a certain angle, place it in the bucket of \n",
    "water, let the water ripples settle down, then save the oscilloscope data. How do we save the oscilloscope data? It is best to use the python console and import `scope` module. Create the output directory, and create a Scope object, passing the directory (as a numpy path) as a parameter. Finally, run `scope.Scope.grab()` to make a single measurement, and the signal will be saved as an `.npy` file in the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py.scope as scope\n",
    "\n",
    "out_folder = \"C:\\\\Users\\\\dionysius\\\\Desktop\\\\PURE\\\\pure\\\\data\\\\TEST_TRANS\"\n",
    "o = scope.Scope(out_folder, filename='test_scope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.grab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How do I analyze a dataset obtained in the angle dependence experiment?\n",
    "\n",
    "You will need to import `py.main`. First, define a variable for the path to the `.npy` data obtained from the scope. Next, instantiate a Transducer object, and call as shown below. Then, call its `write_all()` method and see if the correct peaks have been selected by viewing the figures saved in the subfolder `signal`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. How do I do a B-Scan on one angle dependence experiment dataset?\n",
    "First load data into a variable using `load_obj` from `main`. Pass the name (listed in '/obj') of the dataset into the function as a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How do I perform a 1D or 2D scan?\n",
    "\n",
    "Look at `scanning.py`, change the variable `SCAN_FOLDER` at the top to the appropriate name, and in the main program call the class `Scan` with parameters `DIMENSIONS` and `START_POS`. `DIMENSIONS` takes a tuple of real values representing the scanning grid in units of metres. `START_POS` can be 'top right', 'bottom right', etc. Grid formed is an TxMxN numpy matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAFT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import \\\n",
    "    reshape as np_reshape, \\\n",
    "    power as np_power, \\\n",
    "    sqrt as np_sqrt, \\\n",
    "    argmin as np_argmin, \\\n",
    "    abs as np_abs, \\\n",
    "    sum as np_sum\n",
    "from os import getcwd\n",
    "from os.path import join, dirname\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` is used for array and general number operations. We alias some `numpy` functions to decrease overhead in the main loop of the program. The functions called from `os` are for system directories and paths to file. `pickle` is used to serialize objects into files. `tqdm` is for progress bar reporting. `matplotlib` is used for plotting graphs. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global min_step, c_0, DEFAULT_ARR_FOLDER\n",
    "global xarr, FD, SD, pbar, T, V, L, T_COMPARE, PRE_OUT, POST_OUT, xni\n",
    "FOLDER_NAME = \"1D-15FOC3in\"  # name of folder containing .pkl data\n",
    "DEFAULT_ARR_FOLDER = join(dirname(getcwd()), \"data\", FOLDER_NAME)  # path to folder\n",
    "#DEFAULT_ARR_FOLDER = getcwd()\n",
    "FOCAL_DEPTH = 0.0381  # 1.5 inch in metres\n",
    "SAMPLE_DEPTH = 2.5*FOCAL_DEPTH  # the depth of the sample\n",
    "min_step = 4e-4  # distance traversed with each step of the motor\n",
    "c_0 = 1498  # speed of sound in water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we establish folder paths, and define parameters and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arr(output_folder=DEFAULT_ARR_FOLDER):\n",
    "    # output_folder: path to folder containing tarr.pkl and varr.pkl\n",
    "    ftarr = join(output_folder, \"tarr.pkl\")\n",
    "    fvarr = join(output_folder, \"varr.pkl\")\n",
    "    with open(ftarr, 'rb') as rd:\n",
    "        tarr = pickle.load(rd)\n",
    "    with open(fvarr, 'rb') as rd:\n",
    "        varr = pickle.load(rd)\n",
    "    return tarr, varr\n",
    "\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array, dtype=float)\n",
    "    return (np.abs(array - value)).argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`load_arr()` outputs time and voltage (2D) arrays. `find_nearest()` finds the index in an array best corresponding to a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarr, varr = load_arr()\n",
    "# Reshape tarr and varr\n",
    "tarr = tarr[:, 0, :]\n",
    "varr = varr[:, 0, :]\n",
    "# Start the array from t=0\n",
    "ZERO = find_nearest(tarr[:, 0], 0)\n",
    "T = tarr[ZERO:, 0]  # 1D, time columns all the same\n",
    "V = varr[ZERO:, :]  # 2D\n",
    "# Split the arrays into Pre and Post focal depth\n",
    "FD = find_nearest(T, 2*FOCAL_DEPTH/c_0)  # focal depth\n",
    "# SD = find_nearest(T, 2*SAMPLE_DEPTH/c_0) + 1  # sample depth\n",
    "SD = len(T)-1\n",
    "PRE = np.flip(V[:FD, :], axis=0)\n",
    "PRE_T = np.flip(T[:FD], axis=0)\n",
    "PRE_OUT = np.empty(np.shape(PRE))\n",
    "POST = V[FD:SD, :]\n",
    "POST_T = T[FD:SD]\n",
    "POST_OUT = np.empty(np.shape(POST))\n",
    "\n",
    "L = np.shape(V)[1]  # number of lateral steps\n",
    "#T_COMPARE = np.empty((L, len(T)))\n",
    "#for l in range(L):\n",
    "#    T_COMPARE[l, :] = T[:]\n",
    "xarr = np.linspace(-L/2, L/2, L)*min_step  # lateral distances\n",
    "xni = np.arange(0, L, 1)  # lateral indices\n",
    "pbar = tqdm(total=SD*L)  # initialize progress bar\n",
    "tstep = np.mean(T[1:]-T[:-1])  # estimate of the timestep\n",
    "xi = 0\n",
    "while xi < 0:\n",
    "    x = xarr[xi]\n",
    "    ti = 0\n",
    "    while ti < SD:\n",
    "        pbar.update(1)  # update progress bar\n",
    "        z = T[ti]*c_0/2  # axial distance\n",
    "        z2 = np_power(z, 2)\n",
    "        if ti < FD:  # PRE\n",
    "            ind = ((2/c_0)*np_sqrt(np_power(x-xarr[xni], 2)\n",
    "                   + z2)).reshape((L, 1))  # delayed time\n",
    "            # find index of delayed time\n",
    "#            zi = np_abs(T_COMPARE - ind).argmin(axis=1)  # more accurate\n",
    "            zi = np.floor(ind/tstep).astype(int)  # less accurate, computationally efficient\n",
    "            PRE_OUT[ti, xi] = np_sum(V[zi[zi < FD], xi])  # zi<SD performs SAFT on PRE and POST\n",
    "        if ti >= FD:  # POST\n",
    "            ind = ((2/c_0)*np_sqrt(np_power(x-xarr[xni], 2)\n",
    "                   + z2)).reshape((L, 1))  # delayed time\n",
    "            # find index of delayed time\n",
    "#            zi = np_abs(T_COMPARE - ind).argmin(axis=1)  # more accurate\n",
    "            zi = np.floor(ind/tstep).astype(int)  # less accurate, computationally efficient\n",
    "            POST_OUT[ti-FD, xi] = np_sum(V[zi[zi < SD], xi])\n",
    "        ti += 1\n",
    "        pbar.set_description('xi {0}, ti {1}:\\t'.format(xi, ti))\n",
    "    xi += 1\n",
    "\n",
    "pbar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
