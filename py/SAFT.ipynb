{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setpinski [19], wavenumber algorithm [16], [17]\n",
    "\n",
    "1. Split the data pre focal region and post focal region\n",
    "\n",
    "2. Prefocal consists of electro-mechanical impulse response and excitation pulse ($s_\\text{pre}(x_n,t)$ and $h_\\text{pre}(t)$) is reversed in axial direction\n",
    "\n",
    "3. 2D FFT on all data to get $S(k_x, \\omega), H(\\omega), P(\\omega)$. Far field directivity pattern of VS is assumed to be $A=jinc^2(k_xa)$ , where $a$ is radius of the flat circular virtual source that can be determined from the simulated beam profile.\n",
    "\n",
    "(see: \n",
    "\n",
    "https://en.wikipedia.org/wiki/Sombrero_function, \n",
    "\n",
    "https://en.wikipedia.org/wiki/Bessel_function#Bessel_functions_of_the_first_kind:_J%CE%B1, \n",
    "\n",
    "https://www.johndcook.com/blog/2012/02/02/how-to-compute-jincx/)\n",
    "\n",
    "4. Image reconstruction\n",
    "$$F(k_x, k_z)=\\mathcal{S}\\left\\{\\exp\\left[j(\\sqrt{4k^2-k_x^2}-2k)z_c\\right]A^*\\omega^2H^*(\\omega)P^*(\\omega)S(k_x,\\omega)\\right\\}$$\n",
    "\n",
    "where $\\mathcal{S}\\{\\cdot\\}$ is the Stolt transformation. $z_c$ is the perpendicular distance from the transducer to the midpoint of the ROI. $k=\\omega/c$. \n",
    "\n",
    "Stolt migration:\n",
    "\n",
    "http://sepwww.stanford.edu/sep/prof/iei/omk/paper_html/node11.html\n",
    "\n",
    "https://www.math.ucdavis.edu/~saito/data/sonar/stolt.pdf\n",
    "\n",
    "5. 2D IFFT on $F_\\text{pre}$ and $F_\\text{post}$ to spatial domain, $F_\\text{pre}$ flipped axially, and then stitched together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD-SAFT\n",
    "\n",
    "Image reconstruction is done by delaying the recorded echo signals according to the relative positions of the image pixel and the transducer, which is then followed by a coherent summation. Each point $(x,z)$ in the image is brought into focus by applying appropriate time-delays to the recorded echo data $s(x_n,t)$ for all the transducer positions $x_n(n\\in\\{0\\ldots L-1\\})$ in the synthetic aperture and then performing summation as follows,\n",
    "$$f_\\text{TD}(x,z)=\\sum_{n=0}^{L-1}s\\left(x_n, \\dfrac{2}{c_0}\\sqrt{(x-x_n)^2+z^2}\\right)$$\n",
    "\n",
    "where $c_0$ is the speed of sound, and $f_\\text{TD}(x,z)$ is the reconstructed TD-SAFT image.\n",
    "\n",
    "The time-domain virtual point source SAFT (TD-SAFT-VPS), treats the focus of the transducer as a point source where the above equation is applied in the pre-focal and post-focal regions separately. In the pre-focal region, the recorded echo data is flipped in the axial direction and then DAS is applied. In the post-focal region, DAS is applied to the recorded echo data without changing the orientation of the data. After applying DAS, the pre-focal region is flipped back to its original orientation before joining it with the post-focal region. **In addition, the image intensity of each point can be normalized by dividing the square root of the number of scanlines used at each point.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-68-07766c906906>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-68-07766c906906>\"\u001b[1;36m, line \u001b[1;32m24\u001b[0m\n\u001b[1;33m    results = pool.starmap(smm, [(xi, T=T, V=V, xarr=xarr, tstep=tstep) for xi in range(len(xarr))])\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import getcwd\n",
    "from os.path import join, dirname\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "global min_step, c_0\n",
    "FOLDER_NAME = \"1D-15FOC3in\"\n",
    "FOCAL_DEPTH = 0.0381  # 1.5 inch in metres\n",
    "min_step = 4e-4\n",
    "c_0 = 1498  # water\n",
    "c_1 = 6420  # aluminium\n",
    "\n",
    "\n",
    "# Load voltage data\n",
    "def load_arr(output_folder= join(dirname(getcwd()), \"data\", FOLDER_NAME)):\n",
    "    ftarr = join(output_folder, \"tarr.pkl\")\n",
    "    fvarr = join(output_folder, \"varr.pkl\")\n",
    "    with open(ftarr, 'rb') as rd:\n",
    "        tarr = pickle.load(rd)\n",
    "    with open(fvarr, 'rb') as rd:\n",
    "        varr = pickle.load(rd)\n",
    "    return tarr, varr\n",
    "\n",
    "\n",
    "tarr, varr = load_arr()\n",
    "tarr = tarr[:, 0, :]\n",
    "tstep = np.mean(tarr[1:, :] - tarr[:-1, :])\n",
    "varr = varr[:, 0, :]\n",
    "\n",
    "\n",
    "# express z in terms of indices\n",
    "def t(z):\n",
    "    return (2*z/c_0)//tstep\n",
    "\n",
    "\n",
    "# check if elements of tarr differ along axis=1\n",
    "eq = tarr[:, 1:] == tarr[:, :-1]\n",
    "con = False in eq\n",
    "\n",
    "\n",
    "def delay_t(x, z):\n",
    "    return lambda xn : (2/c_0)*np.sqrt((x-xn)**2+z)\n",
    "\n",
    "\n",
    "def smm(xi, T, V, xarr, tstep):\n",
    "    x = xarr[xi]  # metres\n",
    "    for ti in range(len(T)):\n",
    "        z = T[ti]*c_0/2  # metres\n",
    "        dt = delay_t(x, z)  # anon function dependent on xn\n",
    "        s = 0  # summation\n",
    "        for xn in xarr:\n",
    "            s += V(int(dt(xn)//tstep, xi))\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def SAFT(T, V):\n",
    "    T = T[:, 0]  # time values, 1D\n",
    "    tstep = np.mean(T[1:, :] - T[:-1, :])\n",
    "    xarr = np.arange(0, np.shape(V)[1], 1)*min_step  # lateral distance, 1D\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    results = pool.starmap(smm, [(xi, T=T, V=V, xarr=xarr, tstep=tstep) for xi in range(len(xarr))])\n",
    "    pool.close()\n",
    "    return results\n",
    "                   \n",
    "# Split data into pre and post focal depth\n",
    "FD = int((2*FOCAL_DEPTH/c_0)//tstep) # FOCAL_DEPTH_IND\n",
    "PRE_V = np.flip(varr[:FD+1, :], axis=0)\n",
    "PRE_T = np.flip(tarr[:FD+1])\n",
    "POST_V = varr[FD+1:, :]\n",
    "POST_T = tarr[FD+1:]\n",
    "\n",
    "arr = SAFT(PRE_T, PRE_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-daacb0367254>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mout_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "out_arr = np.empty(np.shape(varr)[1], dtype=float)\n",
    "for x in range(len(xarr)):\n",
    "    for z in range(len(varr)):\n",
    "        s = 0\n",
    "        for n in range(len(xarr)):\n",
    "            xn = xarr[n]\n",
    "            t = int((2/c_0)*np.sqrt((x*min_step - xn)**2 + z**2)//tstep)\n",
    "            s += varr[t, xn]\n",
    "        out_arr[z, x] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5086.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
